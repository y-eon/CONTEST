{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"음성합성.ipynb","provenance":[],"authorship_tag":"ABX9TyOoKOxRqEamWKqBBDJWD4Gk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"DpAi9SJKB7TD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1600329904512,"user_tz":-540,"elapsed":1172,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"db9bfa3d-578f-425b-d73e-e9ee7a6f3d04"},"source":["!git clone https://github.com/hccho2/Tacotron2-Wavenet-Korean-TTS.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["fatal: destination path 'Tacotron2-Wavenet-Korean-TTS' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JUMoM1HGPeCR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":631},"executionInfo":{"status":"ok","timestamp":1600329945819,"user_tz":-540,"elapsed":41966,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"ec84bb0a-94ff-444f-a3e0-55185458661f"},"source":["!pip uninstall tensorflow\n","!pip install tensorflow==1.8.0"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-1.8.0:\n","  Would remove:\n","    /usr/local/bin/freeze_graph\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.6/dist-packages/external/*\n","    /usr/local/lib/python3.6/dist-packages/tensorflow-1.8.0.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n","Proceed (y/n)? y\n","  Successfully uninstalled tensorflow-1.8.0\n","Collecting tensorflow==1.8.0\n","  Using cached https://files.pythonhosted.org/packages/22/c6/d08f7c549330c2acc1b18b5c1f0f8d9d2af92f54d56861f331f372731671/tensorflow-1.8.0-cp36-cp36m-manylinux1_x86_64.whl\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.15.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.35.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.18.5)\n","Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (3.12.4)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.32.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.3.3)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.10.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.1.0)\n","Requirement already satisfied: tensorboard<1.9.0,>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (1.8.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.8.0) (0.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.8.0) (50.3.0)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (1.0.1)\n","Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (1.5.0)\n","Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (0.9999999)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (3.2.2)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (1.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0) (3.1.0)\n","Installing collected packages: tensorflow\n","Successfully installed tensorflow-1.8.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lnFHACUAPkTC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":271},"executionInfo":{"status":"ok","timestamp":1600329946527,"user_tz":-540,"elapsed":2161,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"066df17f-b5a2-4c49-ee65-c219b35cb12f"},"source":["import tensorflow as tf\n","tf.__version__"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.8.0'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"2VEwieGTPpmJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":199},"executionInfo":{"status":"ok","timestamp":1600329953404,"user_tz":-540,"elapsed":8266,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"1912c0eb-51b5-482b-8386-11d3ab376db9"},"source":["!pip install jamo\n","!pip install unidecode"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting jamo\n","  Downloading https://files.pythonhosted.org/packages/ac/cc/49812faae67f9a24be6ddaf58a2cf7e8c3cbfcf5b762d9414f7103d2ea2c/jamo-0.4.1-py3-none-any.whl\n","Installing collected packages: jamo\n","Successfully installed jamo-0.4.1\n","Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\u001b[K     |████████████████████████████████| 245kB 2.8MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wm5LdNxUPvrO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600329953405,"user_tz":-540,"elapsed":6223,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}}},"source":["import os\n","os.getcwd()\n","os.chdir('/content/Tacotron2-Wavenet-Korean-TTS')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"1enXsRzwGTJb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600330053682,"user_tz":-540,"elapsed":34759,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"123f376c-5717-4827-c04e-666298984443"},"source":["!python preprocess.py --num_workers 10 --name moon --in_dir ./datasets/moon --out_dir ./data/moon"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","Hyperparameters:\n","  adam_beta1: 0.9\n","  adam_beta2: 0.999\n","  allow_clipping_in_normalization: True\n","  attention_dim: 128\n","  attention_filters: 32\n","  attention_kernel: (31,)\n","  attention_size: 128\n","  attention_type: bah_mon_norm\n","  attention_win_size: 7\n","  cleaners: korean_cleaners\n","  clip_mels_length: True\n","  cumulative_weights: True\n","  dec_prenet_sizes: [256, 256]\n","  decoder_layers: 2\n","  decoder_lstm_units: 1024\n","  dilation_channels: 256\n","  dilations: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n","  dropout_prob: 0.5\n","  embedding_size: 512\n","  enc_conv_channels: 512\n","  enc_conv_kernel_size: 5\n","  enc_conv_num_layers: 3\n","  encoder_lstm_units: 256\n","  fft_size: 2048\n","  filter_width: 3\n","  gc_channels: 32\n","  griffin_lim_iters: 60\n","  hop_size: 300\n","  inference_prenet_dropout: True\n","  initial_data_greedy: True\n","  initial_phase_step: 8000\n","  input_type: raw\n","  l2_regularization_strength: 0\n","  legacy: True\n","  main_data: ['']\n","  main_data_greedy_factor: 0\n","  mask_encoder: True\n","  max_abs_value: 4.0\n","  max_checkpoints: 3\n","  max_mel_frames: 1000\n","  max_n_frame: 1000\n","  min_level_db: -100\n","  min_n_frame: 150\n","  min_tokens: 30\n","  model_type: multi-speaker\n","  momentum: 0.9\n","  name: Tacotron-2\n","  num_mels: 80\n","  num_steps: 1000000\n","  optimizer: adam\n","  out_channels: 30\n","  post_bank_channel_size: 128\n","  post_bank_size: 8\n","  post_highway_depth: 4\n","  post_maxpool_width: 2\n","  post_proj_sizes: [256, 80]\n","  post_proj_width: 3\n","  post_rnn_size: 128\n","  postnet_channels: 512\n","  postnet_kernel_size: (5,)\n","  postnet_num_layers: 5\n","  power: 1.5\n","  preemphasis: 0.97\n","  preemphasize: True\n","  prenet_layers: [256, 256]\n","  prioritize_loss: False\n","  quantization_channels: 256\n","  reduction_factor: 2\n","  ref_level_db: 20\n","  rescaling: True\n","  rescaling_max: 0.999\n","  residual_channels: 128\n","  residual_legacy: True\n","  sample_rate: 24000\n","  sample_size: 9000\n","  scalar_input: True\n","  signal_normalization: True\n","  silence_threshold: 0\n","  skip_channels: 128\n","  skip_inadequate: False\n","  skip_path_filter: False\n","  smoothing: False\n","  speaker_embedding_size: 16\n","  store_metadata: False\n","  symmetric_mels: True\n","  synthesis_constraint: False\n","  synthesis_constraint_type: window\n","  tacotron_decay_learning_rate: True\n","  tacotron_decay_rate: 0.5\n","  tacotron_decay_steps: 18000\n","  tacotron_final_learning_rate: 0.0001\n","  tacotron_initial_learning_rate: 0.001\n","  tacotron_reg_weight: 1e-06\n","  tacotron_start_decay: 40000\n","  tacotron_zoneout_rate: 0.1\n","  trim_fft_size: 512\n","  trim_hop_size: 128\n","  trim_silence: True\n","  trim_top_db: 23\n","  upsample_factor: [12, 25]\n","  upsample_type: SubPixel\n","  use_biases: True\n","  use_lws: False\n","  wavenet_batch_size: 2\n","  wavenet_clip_gradients: True\n","  wavenet_decay_rate: 0.5\n","  wavenet_decay_steps: 300000\n","  wavenet_dropout: 0.05\n","  wavenet_learning_rate: 0.001\n","  win_size: 1200\n","Sampling frequency: 24000\n","100% 109/109 [00:28<00:00,  3.83it/s]\n","Write 109 utterances, 13624 mel frames, 4087200 audio timesteps, (0.05 hours)\n","Max input length (text chars): 25\n","Max mel frames length: 340\n","Max audio timesteps length: 102000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tA_fce8mfxeT","colab_type":"code","colab":{}},"source":["# train_tacotron2 : main 함수에서 data__path에 하나만 지정, load_path =none으로 변경\n","# hparams : model_type single로 변경"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hk1-XVChWlr7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"c5ba8be3-3a26-46f1-bd96-231b65bbe618"},"source":["!python train_tacotron2.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"," [*] MODEL dir: logdir-tacotron2/moon_2020-09-17_08-29-29\n"," [*] PARAM path: logdir-tacotron2/moon_2020-09-17_08-29-29/params.json\n","['/content/Tacotron2-Wavenet-Korean-TTS/data/moon']\n","==================================================\n","==================================================\n"," [*] Checkpoint path: logdir-tacotron2/moon_2020-09-17_08-29-29/model.ckpt\n"," [*] Loading training data from: ['/content/Tacotron2-Wavenet-Korean-TTS/data/moon']\n"," [*] Using model: logdir-tacotron2/moon_2020-09-17_08-29-29\n","Hyperparameters:\n","  adam_beta1: 0.9\n","  adam_beta2: 0.999\n","  allow_clipping_in_normalization: True\n","  attention_dim: 128\n","  attention_filters: 32\n","  attention_kernel: (31,)\n","  attention_size: 128\n","  attention_type: bah_mon_norm\n","  attention_win_size: 7\n","  cleaners: korean_cleaners\n","  clip_mels_length: True\n","  cumulative_weights: True\n","  dec_prenet_sizes: [256, 256]\n","  decoder_layers: 2\n","  decoder_lstm_units: 1024\n","  dilation_channels: 256\n","  dilations: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n","  dropout_prob: 0.5\n","  embedding_size: 512\n","  enc_conv_channels: 512\n","  enc_conv_kernel_size: 5\n","  enc_conv_num_layers: 3\n","  encoder_lstm_units: 256\n","  fft_size: 2048\n","  filter_width: 3\n","  gc_channels: 32\n","  griffin_lim_iters: 60\n","  hop_size: 300\n","  inference_prenet_dropout: True\n","  initial_data_greedy: True\n","  initial_phase_step: 8000\n","  input_type: raw\n","  l2_regularization_strength: 0\n","  legacy: True\n","  main_data: ['']\n","  main_data_greedy_factor: 0\n","  mask_encoder: True\n","  max_abs_value: 4.0\n","  max_checkpoints: 3\n","  max_mel_frames: 1000\n","  max_n_frame: 1000\n","  min_level_db: -100\n","  min_n_frame: 150\n","  min_tokens: 30\n","  model_type: single\n","  momentum: 0.9\n","  name: Tacotron-2\n","  num_mels: 80\n","  num_steps: 1000000\n","  optimizer: adam\n","  out_channels: 30\n","  post_bank_channel_size: 128\n","  post_bank_size: 8\n","  post_highway_depth: 4\n","  post_maxpool_width: 2\n","  post_proj_sizes: [256, 80]\n","  post_proj_width: 3\n","  post_rnn_size: 128\n","  postnet_channels: 512\n","  postnet_kernel_size: (5,)\n","  postnet_num_layers: 5\n","  power: 1.5\n","  preemphasis: 0.97\n","  preemphasize: True\n","  prenet_layers: [256, 256]\n","  prioritize_loss: False\n","  quantization_channels: 256\n","  reduction_factor: 2\n","  ref_level_db: 20\n","  rescaling: True\n","  rescaling_max: 0.999\n","  residual_channels: 128\n","  residual_legacy: True\n","  sample_rate: 24000\n","  sample_size: 9000\n","  scalar_input: True\n","  signal_normalization: True\n","  silence_threshold: 0\n","  skip_channels: 128\n","  skip_inadequate: False\n","  skip_path_filter: False\n","  smoothing: False\n","  speaker_embedding_size: 16\n","  store_metadata: False\n","  symmetric_mels: True\n","  synthesis_constraint: False\n","  synthesis_constraint_type: window\n","  tacotron_decay_learning_rate: True\n","  tacotron_decay_rate: 0.5\n","  tacotron_decay_steps: 18000\n","  tacotron_final_learning_rate: 0.0001\n","  tacotron_initial_learning_rate: 0.001\n","  tacotron_reg_weight: 1e-06\n","  tacotron_start_decay: 40000\n","  tacotron_zoneout_rate: 0.1\n","  trim_fft_size: 512\n","  trim_hop_size: 128\n","  trim_silence: True\n","  trim_top_db: 23\n","  upsample_factor: [12, 25]\n","  upsample_type: SubPixel\n","  use_biases: True\n","  use_lws: False\n","  wavenet_batch_size: 2\n","  wavenet_clip_gradients: True\n","  wavenet_decay_rate: 0.5\n","  wavenet_decay_steps: 300000\n","  wavenet_dropout: 0.05\n","  wavenet_learning_rate: 0.001\n","  win_size: 1200\n","filter_by_min_max_frame_batch: 100% 109/109 [00:00<00:00, 527.36it/s]\n"," [/content/Tacotron2-Wavenet-Korean-TTS/data/moon] Loaded metadata for 34 examples (0.02 hours)\n"," [/content/Tacotron2-Wavenet-Korean-TTS/data/moon] Max length: 340\n"," [/content/Tacotron2-Wavenet-Korean-TTS/data/moon] Min length: 152\n","========================================\n","Data Amount:\n","{'/content/Tacotron2-Wavenet-Korean-TTS/data/moon': 1.0}\n","========================================\n","filter_by_min_max_frame_batch: 100% 109/109 [00:00<00:00, 452.08it/s]\n"," [/content/Tacotron2-Wavenet-Korean-TTS/data/moon] Loaded metadata for 34 examples (0.02 hours)\n"," [/content/Tacotron2-Wavenet-Korean-TTS/data/moon] Max length: 340\n"," [/content/Tacotron2-Wavenet-Korean-TTS/data/moon] Min length: 152\n","========================================\n","Data Amount:\n","{'/content/Tacotron2-Wavenet-Korean-TTS/data/moon': 1.0}\n","========================================\n","========================================\n"," model_type: single\n","========================================\n","Initialized Tacotron model. Dimensions: \n","    embedding:                512\n","    encoder conv out:               512\n","    encoder out:              512\n","    attention out:            1024\n","    decoder prenet lstm concat out :        1536\n","    decoder cell out:         162\n","    decoder out (2 frames):  162\n","    decoder mel out:    80\n","    mel out:    80\n","    postnet out:              256\n","    linear out:               1025\n","  Tacotron Parameters       29.142 Million.\n","========================================\n"," model_type: single\n","========================================\n","Initialized Tacotron model. Dimensions: \n","    embedding:                512\n","    encoder conv out:               512\n","    encoder out:              512\n","    attention out:            1024\n","    decoder prenet lstm concat out :        1536\n","    decoder cell out:         162\n","    decoder out (2 frames):  162\n","    decoder mel out:    80\n","    mel out:    80\n","    postnet out:              256\n","    linear out:               1025\n","  Tacotron Parameters       29.142 Million.\n","2020-09-17 08:29:44.240532: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","Starting new training run at commit: None\n","Generated 8 batches of size 2 in 0.000 sec\n","Generated 32 batches of size 32 in 5.589 sec\n","Step 1       [34.295 sec/step, loss=7.52292, avg_loss=7.52292]\n","Step 2       [30.778 sec/step, loss=6.10788, avg_loss=6.81540]\n","Step 3       [29.561 sec/step, loss=5.57085, avg_loss=6.40055]\n","Step 4       [28.932 sec/step, loss=5.64463, avg_loss=6.21157]\n","Step 5       [29.425 sec/step, loss=7.57536, avg_loss=6.48433]\n","Step 6       [29.015 sec/step, loss=5.62019, avg_loss=6.34030]\n","Step 7       [29.344 sec/step, loss=5.41758, avg_loss=6.20849]\n","Step 8       [29.045 sec/step, loss=4.28817, avg_loss=5.96845]\n","Step 9       [29.256 sec/step, loss=4.44573, avg_loss=5.79926]\n","Step 10      [29.000 sec/step, loss=3.67353, avg_loss=5.58668]\n","Step 11      [29.204 sec/step, loss=3.91956, avg_loss=5.43513]\n","Step 12      [29.007 sec/step, loss=3.25555, avg_loss=5.25349]\n","Step 13      [29.172 sec/step, loss=3.66253, avg_loss=5.13111]\n","Step 14      [29.028 sec/step, loss=3.03303, avg_loss=4.98125]\n","Step 15      [28.902 sec/step, loss=2.93977, avg_loss=4.84515]\n","Step 16      [29.057 sec/step, loss=3.55328, avg_loss=4.76441]\n","Step 17      [29.205 sec/step, loss=3.58310, avg_loss=4.69492]\n","Step 18      [29.097 sec/step, loss=2.82014, avg_loss=4.59077]\n","Step 19      [29.225 sec/step, loss=3.31237, avg_loss=4.52348]\n","Step 20      [29.128 sec/step, loss=2.67546, avg_loss=4.43108]\n","Step 21      [29.222 sec/step, loss=3.07580, avg_loss=4.36654]\n","Step 22      [29.308 sec/step, loss=2.93746, avg_loss=4.30158]\n","Step 23      [29.182 sec/step, loss=2.52603, avg_loss=4.22439]\n","Generated 32 batches of size 32 in 6.544 sec\n","Step 24      [29.185 sec/step, loss=2.46608, avg_loss=4.15112]\n","Step 25      [29.089 sec/step, loss=2.40200, avg_loss=4.08116]\n","Step 26      [29.009 sec/step, loss=2.32648, avg_loss=4.01367]\n","Step 27      [29.108 sec/step, loss=2.67130, avg_loss=3.96395]\n","Step 28      [29.193 sec/step, loss=2.56469, avg_loss=3.91398]\n","Step 29      [29.279 sec/step, loss=2.48181, avg_loss=3.86460]\n","Step 30      [29.362 sec/step, loss=2.41096, avg_loss=3.81614]\n","Step 31      [29.428 sec/step, loss=2.36528, avg_loss=3.76934]\n","Step 32      [29.489 sec/step, loss=2.32222, avg_loss=3.72412]\n","Step 33      [29.551 sec/step, loss=2.26262, avg_loss=3.67983]\n","Step 34      [29.604 sec/step, loss=2.21347, avg_loss=3.63670]\n","Step 35      [29.656 sec/step, loss=2.17167, avg_loss=3.59484]\n","Step 36      [29.705 sec/step, loss=2.13247, avg_loss=3.55422]\n","Step 37      [29.636 sec/step, loss=2.25243, avg_loss=3.51904]\n","Step 38      [29.693 sec/step, loss=2.09091, avg_loss=3.48146]\n","Step 39      [29.629 sec/step, loss=2.06843, avg_loss=3.44522]\n","Step 40      [29.682 sec/step, loss=2.05427, avg_loss=3.41045]\n","Step 41      [29.622 sec/step, loss=1.96457, avg_loss=3.37518]\n","Step 42      [29.565 sec/step, loss=1.91854, avg_loss=3.34050]\n","Step 43      [29.513 sec/step, loss=1.87088, avg_loss=3.30633]\n","Step 44      [29.462 sec/step, loss=1.82481, avg_loss=3.27265]\n","Step 45      [29.414 sec/step, loss=1.78671, avg_loss=3.23963]\n","Step 46      [29.367 sec/step, loss=1.75664, avg_loss=3.20739]\n","Step 47      [29.313 sec/step, loss=1.72415, avg_loss=3.17584]\n","Step 48      [29.354 sec/step, loss=2.01333, avg_loss=3.15162]\n","Step 49      [29.303 sec/step, loss=1.67062, avg_loss=3.12139]\n","Step 50      [29.257 sec/step, loss=1.64667, avg_loss=3.09190]\n","Step 51      [29.213 sec/step, loss=1.62115, avg_loss=3.06306]\n","Step 52      [29.252 sec/step, loss=1.85017, avg_loss=3.03974]\n","Step 53      [29.286 sec/step, loss=1.78742, avg_loss=3.01611]\n","Step 54      [29.243 sec/step, loss=1.58767, avg_loss=2.98965]\n","Step 55      [29.278 sec/step, loss=1.70827, avg_loss=2.96636]\n","Generated 32 batches of size 32 in 6.779 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6t5B_hMAM0Ga","colab_type":"code","colab":{}},"source":["#train_voder에서 data_directory moon 변경, logdir=none으로 변경"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SUG3rsVQWlfi","colab_type":"code","colab":{}},"source":["!python train_vocoder.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xcul4mZMOuz","colab_type":"code","colab":{}},"source":["!python synthesizer.py --load_path logdir-tacotron2/moon+son_2019-02-27_00-21-42 --num_speakers 1 --speaker_id 0 --text \"오스트랄로피테쿠스 아파렌시스는 멸종된 사람족 종으로, 현재에는 뼈 화석이 발견되어 있다\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uzmamT11MOmo","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b1Xe3S8DMOeT","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XlyU_kvMOWL","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FkVIac4lMNow","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vbe2jIjsWlYN","colab_type":"code","colab":{}},"source":["# python synthesizer.py --load_path logdir-tacotron2/moon+son_2019-02-27_00-21-42 --num_speakers 2 --speaker_id 0 --text \"오스트랄로피테쿠스 아파렌시스는 멸종된 사람족 종으로, 현재에는 뼈 화석이 발견되어 있다\"\n","# python synthesizer.py --load_path logdir-tacotron2/moon+son_2019-02-27_00-21-42 --num_speakers 2 --speaker_id 1 --text \"오스트랄로피테쿠스 아파렌시스는 멸종된 사람족 종으로, 현재에는 뼈 화석이 발견되어 있다\"\n","\n","# python generate.py --mel ./logdir-wavenet/mel-moon.npy --gc_cardinality 2 --gc_id 0 ./logdir-wavenet/train/2019-03-27T20-27-18\n","# python generate.py --mel ./logdir-wavenet/mel-son.npy --gc_cardinality 2 --gc_id 1 ./logdir-wavenet/train/2019-03-27T20-27-18\n","# python generate.py --mel ./logdir-wavenet/moon-Aust.npy --gc_cardinality 2 --gc_id 0 ./logdir-wavenet/train/2019-03-27T20-27-18\n","# python generate.py --mel ./logdir-wavenet/son-Aust.npy --gc_cardinality 2 --gc_id 1 ./logdir-wavenet/train/2019-03-27T20-27-18"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9w-YYB2mWgq0","colab_type":"text"},"source":["### KSS Json만들기"]},{"cell_type":"code","metadata":{"id":"fWyYl4AfCMlc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600181708265,"user_tz":-540,"elapsed":22334,"user":{"displayName":"김도연","photoUrl":"","userId":"13093336926317411579"}},"outputId":"85d6ae16-e4e4-4091-97a5-9480f75969be"},"source":["import json\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LWRP72OHLsPU","colab_type":"code","colab":{}},"source":["import pandas as  pd\n","data = pd.read_csv('/content/drive/My Drive/Korean_Single_speaker_Speech_Dataset/transcript.v.1.4.txt',sep='|',names=['audio','text','text1','text2','num','eng'])\n","voice = {}\n","for i in range(len(data)):\n","  voice['{}{}'.format('/content/drive/My Drive/Korean_Single_speaker_Speech_Dataset/voice/',data['audio'].iloc[i])] = data['text'].iloc[i]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBjyxj9XL9sc","colab_type":"code","colab":{}},"source":["voice_recognition_All = json.dumps(voice)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODbL0_Z8OQiD","colab_type":"code","colab":{}},"source":["with open('voice_recognition_All.json','w',encoding='utf-8') as make_file:\n","  json.dump(voice_recognition_All,make_file,ensure_ascii=False,indent='\\t')"],"execution_count":null,"outputs":[]}]}